# flink training

Infrastructure to run this project is defined in docker-compose.yaml

Run docker-compose up -d

This project is made of 2 flink job:

- Taxi-event-generator (thanks Tommy!) generate taxi ride events
- Long-ride-alerts: writes in a Postgres database the id of rides that lasted more than 2 hours.

The settings to access the Postgres db are in docker-compose.yaml

#Approach

Step 1: I started from the squeletton app provided in the Canvas link, then added the missing code until all unit tests passed.
Limitations:
- no separate job for TaxiRide generator
- console output
  
Step 2: Refactored as follows
- Added a separate flink job to generate taxi rides
- Changed the source to Kafka stream, to read data generated by the newly created job
- Modified the sink to write to a Postgres database

#Comments

- Replacing SourceFunction with DataStream made my version incompatible with the unit tests provided in the Canvas initial version.
As I was running out of time, I simply deleted the unit tests.
- During the training on march 28, I tested that I could deploy and run flink jobs with the infrastructure started from  the docker-compose.yaml
- For this lab, I made minor changes (Postgres) to the infrastructure and checked that everything started correctly (I use vagrant instead of docker desktop)
- I also tested that, after running docker-compose up -d and setting and environment variable ENV (used for the snapshots location), I was able to start the generator in IntelliJ, start the pipeline in IntelliJ and tested that events were written in the database.
- Running out of time, I have not deployed the flink jobs outside IntelliJ, but I am fairly confident that this pipeline works!






